{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Utilisation de vectorize et guvectorize\n",
    "\n",
    "Numba fournie deux autres fonctionalités (vectorize et guvectorize) permettant d'accélérer des fonctions universelles NumPy (ufuncs). Avant d'aller plus loin, rappelons ce qu'est une ufunc.\n",
    "\n",
    "Une ufunc est une fonction qui agit élément par élément pour un tableau donné. Elle permet de vectoriser les opérations et elle est définie de la manière suivante: les paramètres d'entrée sont des scalaires et le paramètre de sortie est également un scalaire. \n",
    "\n",
    "Prenons par exemple la fonction heaviside qui est définie de la manière suivante\n",
    "\n",
    "$$\n",
    "heaviside(x, h_0) = \n",
    "\\left\\{\n",
    "\\begin{array}{l}\n",
    "0 \\; \\text{si} \\; x<0, \\\\\n",
    "h_0 \\; \\text{si} \\; x=0, \\\\\n",
    "1 \\; \\text{si} \\; x>0.\n",
    "\\end{array}\n",
    "\\right.\n",
    "$$\n",
    "\n",
    "Les ufuncs sont codées en C dans NumPy et sont donc optimisées. Voici la version de la fonction heaviside dans NumPy (attention, cette fonction n'est disponible qu'à partir de la dernière version: 1.13)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```C\n",
    "/**begin repeat\n",
    " * #type = npy_float, npy_double, npy_longdouble#\n",
    " * #c = f, ,l#\n",
    " * #C = F, ,L#\n",
    " */\n",
    "\n",
    "@type@ npy_heaviside@c@(@type@ x, @type@ h0)\n",
    "{\n",
    "    if (npy_isnan(x)) {\n",
    "        return (@type@) NPY_NAN;\n",
    "    }\n",
    "    else if (x == 0) {\n",
    "        return h0;\n",
    "    }\n",
    "    else if (x < 0) {\n",
    "        return (@type@) 0.0;\n",
    "    }\n",
    "    else {\n",
    "        return (@type@) 1.0;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vous pouvez le voir ce n'est pas très lisible et surtout, vous n'avez certainement pas envie de faire une interface C pour une fonction simple. (voir si on peut prendre un autre exemple)\n",
    "\n",
    "**vectorize** et **guvectorize** sont donc là pour vous aider à construire des ufuncs tout en restant en Python.\n",
    "\n",
    "## vectorize\n",
    "\n",
    "Voici comment la fonction heaviside s'écrit en Numba en utilisant **vectorize**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize(['float64(float64, float64)'])\n",
    "def heaviside(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x = -1 + 2*np.random.random(1000000)\n",
    "h0 = .4 \n",
    "numba_res = heaviside(x, h0)\n",
    "numpy_res = np.heaviside(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(numba_res == numpy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 20.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit heaviside(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 8.04 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit np.heaviside(x, h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La fonction Numba est 2.5 fois plus lente que la fonction NumPy. On peut accélérer un peu les choses en spécifiant la cible. En effet, **vectorize** a un mot clé **target** indiquant\n",
    "\n",
    "- 'cpu'\n",
    "\n",
    "fonction pour un thread sur CPU\n",
    "\n",
    "- 'parallel'\n",
    "\n",
    "fonction multi-threads pour CPU\n",
    "\n",
    "- 'cuda'\n",
    "\n",
    "fonction utilisant cuda sur GPU\n",
    "\n",
    "Voyons ce que ça donne si nous mettons cette fonction en parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='parallel')\n",
    "def heaviside_para(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On l'appelle une première fois pour ne pas prendre en compte le temps de compilation dans le calcul de la performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numba_res_para = heaviside_para(x, h0)\n",
    "np.all(numba_res_para == numpy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 7.75 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit heaviside_para(x, h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous sommes cette fois un peu plus rapide que la fonction NumPy. Mais il faut noté que la version NumPy n'est pas parallèle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)'], target='cuda')\n",
    "def heaviside_gpu(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "CudaSupportError",
     "evalue": "Error at driver init: \n[999] Call to cuInit results in CUDA_ERROR_UNKNOWN:",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCudaAPIError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0m_logger\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'init'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 225\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    226\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCudaAPIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36msafe_cuda_api_call\u001b[0;34m(*args)\u001b[0m\n\u001b[1;32m    287\u001b[0m             \u001b[0mretcode\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlibfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretcode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0msafe_cuda_api_call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m_check_error\u001b[0;34m(self, fname, retcode)\u001b[0m\n\u001b[1;32m    322\u001b[0m                     \u001b[0;32mraise\u001b[0m \u001b[0mCudaDriverError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"CUDA initialized before forking\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 323\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaAPIError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mretcode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCudaAPIError\u001b[0m: [999] Call to cuInit results in CUDA_ERROR_UNKNOWN",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mCudaSupportError\u001b[0m                          Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3d5cb5d5457e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mheaviside_gpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mh0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kws)\u001b[0m\n\u001b[1;32m     86\u001b[0m                       \u001b[0mthe\u001b[0m \u001b[0minput\u001b[0m \u001b[0marguments\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \"\"\"\n\u001b[0;32m---> 88\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mCUDAUFuncMechanism\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunctions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0marg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/npyufunc/deviceufunc.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(cls, typemap, args, kws)\u001b[0m\n\u001b[1;32m    288\u001b[0m                 \u001b[0many_device\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 290\u001b[0;31m                 \u001b[0mdev_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    291\u001b[0m                 \u001b[0mdevarys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_a\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    292\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/dispatcher.py\u001b[0m in \u001b[0;36mto_device\u001b[0;34m(self, hostary, stream)\u001b[0m\n\u001b[1;32m    201\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    202\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 203\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhostary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    204\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mto_host\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevary\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstream\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m_require_cuda_context\u001b[0;34m(*args, **kws)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mfunctools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwraps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_require_cuda_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mget_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkws\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36mget_context\u001b[0;34m(devnum)\u001b[0m\n\u001b[1;32m    192\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mCUDA\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m     \"\"\"\n\u001b[0;32m--> 194\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_runtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_or_create_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36mget_or_create_context\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m    160\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    161\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 162\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpush_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgpus\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    163\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    164\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mreset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, devnum)\u001b[0m\n\u001b[1;32m     38\u001b[0m         \u001b[0mReturns\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0mmanager\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mdevice\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m         '''\n\u001b[0;32m---> 40\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlst\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdevnum\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__str__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/devices.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0;31m# Device list is not initialized.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0;31m# Query all CUDA devices.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mnumdev\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdriver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m             gpus = [_DeviceContextManager(driver.get_device(devid))\n\u001b[1;32m     28\u001b[0m                     for devid in range(numdev)]\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36mget_device_count\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    332\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_device_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    333\u001b[0m         \u001b[0mcount\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_int\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 334\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuDeviceGetCount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbyref\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    335\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mcount\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    336\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, fname)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;31m# Initialize driver\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_initialized\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 268\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization_error\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/loic/miniconda3/lib/python3.6/site-packages/numba-0.34.0.dev0+402.g5c099e37f-py3.6-linux-x86_64.egg/numba/cuda/cudadrv/driver.py\u001b[0m in \u001b[0;36minitialize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    226\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mCudaAPIError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    227\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitialization_error\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 228\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mCudaSupportError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error at driver init: \\n%s:\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    229\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    230\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_getpid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mCudaSupportError\u001b[0m: Error at driver init: \n[999] Call to cuInit results in CUDA_ERROR_UNKNOWN:"
     ]
    }
   ],
   "source": [
    "heaviside_gpu(x, h0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 8.27 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit heaviside_gpu(x, h0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comme vu lors l'introduction à **@jit**, il est possible de spécialiser une fonction vectorize en donnant les différents types sous forme de liste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@vectorize(['float64(float64, float64)',\n",
    "            'float32(float32, float32)',\n",
    "            'int32(int32, int32)'], target='parallel')\n",
    "def heaviside_para(x, h0):\n",
    "    if x == 0:\n",
    "        return h0\n",
    "    elif x < 0:\n",
    "        return 0.\n",
    "    else:\n",
    "        return 1."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## guvectorize\n",
    "\n",
    "**guvectorize** fait exactement la même chose que **vectorize** à la seule différence que nous n'avons à aucun moment spécifié le tableau de sortie. Celui-ci est donc créé à chaque appel de la fonction. Ce qui peut avoir un coup non négligeable si nous appelons plein de fois la fonction. **guvectorize** permet de mettre le tableau de sortie dans les arguments.\n",
    "\n",
    "Reprenons notre exemple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import guvectorize, njit\n",
    "\n",
    "@njit\n",
    "def heaviside_core1(x, h0, y):\n",
    "    for i in range(x.size):\n",
    "        if x[i] == 0:\n",
    "            y[i] = h0\n",
    "        elif x[i] < 0:\n",
    "            y[i] = 0.\n",
    "        else:\n",
    "            y[i] = 1.        \n",
    "\n",
    "@njit\n",
    "def heaviside_core(x, h0, y):\n",
    "    if x == 0:\n",
    "        y = h0\n",
    "    elif x < 0:\n",
    "        y = 0.\n",
    "    else:\n",
    "        y = 1.        \n",
    "\n",
    "@guvectorize(['void(float64[:], float64[:], float64[:])'], '(),()->()', target='parallel')\n",
    "def guheaviside(x, h0, y):\n",
    "    heaviside_core(x[0], h0[0], y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = np.zeros_like(x)\n",
    "heaviside_core1(x, h0, y)\n",
    "np.all(y == numpy_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.,  0.,  0., ...,  0.,  1.,  1.])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numpy_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 loops, best of 3: 2.77 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit heaviside_core1(x, h0, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from numba import njit\n",
    "\n",
    "@njit\n",
    "def splint(xa, ya, y2a, x, y):\n",
    "    n = xa.shape[0]\n",
    "    for i in range(x.shape[0]):\n",
    "        klo = 0\n",
    "        khi = n-1\n",
    "        while(khi-klo) > 1:\n",
    "            k = (khi+klo) >> 1\n",
    "            if xa[k] > x[i]:\n",
    "                khi = k\n",
    "            else:\n",
    "                klo = k\n",
    "        h = xa[khi] - xa[klo]\n",
    "        a = (xa[khi]-x[i])/h    \n",
    "        b = (x[i]-xa[klo])/h\n",
    "        y[i,:] = a*ya[klo,:]+b*ya[khi,:]+((a**3-a)*y2a[klo,:]+(b**3-b)*y2a[khi,:])*h**2/6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from numba import njit, jit, guvectorize\n",
    "import timeit\n",
    "import numpy as np\n",
    "\n",
    "@njit\n",
    "def square_sum(arr):\n",
    "    a = 0.\n",
    "    for i in range(arr.size):\n",
    "        a = sqrt(a**2 + arr[i]**2)  # sqrt and square are cpu-intensive!\n",
    "    return a\n",
    "\n",
    "@guvectorize([\"void(float64[:], float64[:])\"], \"(n) -> ()\", target=\"parallel\", nopython=True)\n",
    "def row_sum_gu(input, output) :\n",
    "    output[0] = square_sum(input)\n",
    "\n",
    "@jit(nopython=True)\n",
    "def row_sum_jit(input_array, output_array) :\n",
    "    m, n = input_array.shape\n",
    "    for i in range(m) :\n",
    "        output_array[i] = square_sum(input_array[i,:])\n",
    "    return output_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 2.09 s per loop\n",
      "1 loop, best of 3: 663 ms per loop\n"
     ]
    }
   ],
   "source": [
    "rows = int(64)\n",
    "columns = int(1e6)\n",
    "\n",
    "input_array = np.random.random((rows, columns))\n",
    "output_array = np.zeros((rows))\n",
    "output_array2 = np.zeros((rows))\n",
    "\n",
    "# Warmup an check that they are equal \n",
    "np.testing.assert_equal(row_sum_jit(input_array, output_array), row_sum_gu(input_array, output_array2))\n",
    "%timeit row_sum_jit(input_array, output_array.copy())  # 10 loops, best of 3: 130 ms per loop\n",
    "%timeit row_sum_gu(input_array, output_array.copy())   # 10 loops, best of 3: 35.7 ms per loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@njit\n",
    "def square(arr_in, arr_out):\n",
    "    for i in range(arr_in.size):\n",
    "        arr_out[i] = sqrt(arr_in[i])\n",
    "            \n",
    "@guvectorize(['void(float64[:], float64[:])'], \"(n) -> (n)\", target=\"parallel\", nopython=True)\n",
    "def test(input, output):\n",
    "    square(input, output)\n",
    "    \n",
    "@njit\n",
    "def test_jit(input, output):\n",
    "    for i in range(input.shape[0]):\n",
    "        square(input[i], output[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n = 10000\n",
    "input_array = np.random.random((n, n))\n",
    "output_array = np.zeros((n, n))\n",
    "output_array2 = np.zeros((n ,n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 243 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit test(input_array, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 761 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit test_jit(input_array, output_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "@jit\n",
    "def splint_core(xa, ya, y2a, x, y):\n",
    "    klo = 0\n",
    "    khi = xa.shape[0]-1\n",
    "    while(khi-klo) > 1:\n",
    "        k = (khi+klo) >> 1\n",
    "        if xa[k] > x:\n",
    "            khi = k\n",
    "    #    else:\n",
    "    #        klo = k\n",
    "    h = xa[khi] - xa[klo]\n",
    "    a = (xa[khi]-x)/h    \n",
    "    b = (x-xa[klo])/h\n",
    "    y = a*ya[klo]+b*ya[khi]+((a**3-a)*y2a[klo]+(b**3-b)*y2a[khi])*h**2/6.\n",
    "\n",
    "@guvectorize(['void(float64[:], float64[:], float64[:], float64[:], float64[:])'], \"(n),(n),(n),() -> ()\", target=\"parallel\")    \n",
    "def splint_gu(xa, ya, y2a, x, y):\n",
    "    klo = 0\n",
    "    khi = xa.shape[0]-1\n",
    "    while(khi-klo) > 1:\n",
    "        k = (khi+klo) >> 1\n",
    "        if xa[k] > x[0]:\n",
    "            khi = k\n",
    "        else:\n",
    "            klo = k\n",
    "    h = xa[khi] - xa[klo]\n",
    "    a = (xa[khi]-x[0])/h    \n",
    "    b = (x[0]-xa[klo])/h\n",
    "    y[0] = a*ya[klo]+b*ya[khi]+((a**3-a)*y2a[klo]+(b**3-b)*y2a[khi])*h**2/6.\n",
    "    \n",
    "@njit\n",
    "def splint_jit(xa, ya, y2a, x, y):\n",
    "    n = xa.shape[0]\n",
    "    for i in range(x.shape[0]):\n",
    "        klo = 0\n",
    "        khi = n-1\n",
    "        while(khi-klo) > 1:\n",
    "            k = (khi+klo) >> 1\n",
    "            if xa[k] > x[i]:\n",
    "                khi = k\n",
    "            else:\n",
    "                klo = k\n",
    "        h = xa[khi] - xa[klo]\n",
    "        a = (xa[khi]-x[i])/h    \n",
    "        b = (x[i]-xa[klo])/h\n",
    "        y[i] = a*ya[klo]+b*ya[khi]+((a**3-a)*y2a[klo]+(b**3-b)*y2a[khi])*h**2/6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xa = np.linspace(0, 1, 100)\n",
    "ya = np.random.rand(100)\n",
    "y2a = np.random.rand(100)\n",
    "\n",
    "x = np.linspace(0, 1, 1000)\n",
    "y1 = np.zeros_like(x)\n",
    "y2 = np.zeros_like(x)\n",
    "\n",
    "splint_gu(xa, ya, y2a, x, y1)\n",
    "splint_jit(xa, ya, y2a, x, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 114.37 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "10000 loops, best of 3: 64.7 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit splint_gu(xa, ya, y2a, x, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000 loops, best of 3: 135 µs per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit splint_jit(xa, ya, y2a, x, y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.all(y1==y2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 26.9 s per loop\n",
      "1 loop, best of 3: 26.6 s per loop\n",
      "1 loop, best of 3: 12.4 s per loop\n",
      "1 loop, best of 3: 8.98 s per loop\n",
      "True\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from numba import jit, guvectorize, float64, int64\n",
    "\n",
    "@jit\n",
    "def naive_for_loop(some_input_array, another_input_array, result):\n",
    "    for i in range(result.shape[0]):\n",
    "        for k in range(some_input_array.shape[0] - i):\n",
    "            result[i] += some_input_array[k+i] * another_input_array[k] * np.sin(0.001 * (k+i)) \n",
    "\n",
    "@guvectorize([(float64[:],float64[:],int64[:],float64[:])],'(n),(n),()->()', nopython=True, target='parallel')\n",
    "def forall_loop_body_parallel(some_input_array, another_input_array, loop_index, result):\n",
    "    i = loop_index[0]       # just a shorthand\n",
    "    # do some nontrivial calculation involving elements from the input arrays and the loop index\n",
    "    for k in range(some_input_array.shape[0] - i):\n",
    "        result[0] += some_input_array[k+i] * another_input_array[k] * np.sin(0.001 * (k+i)) \n",
    "\n",
    "@guvectorize([(float64[:],float64[:],int64[:],float64[:])],'(n),(n),()->()', nopython=True, target='cpu')\n",
    "def forall_loop_body_cpu(some_input_array, another_input_array, loop_index, result):\n",
    "    i = loop_index[0]       # just a shorthand\n",
    "    # do some nontrivial calculation involving elements from the input arrays and the loop index\n",
    "    for k in range(some_input_array.shape[0] - i):\n",
    "        result[0] += some_input_array[k+i] * another_input_array[k] * np.sin(0.001 * (k+i)) \n",
    "\n",
    "arg_size = 20000\n",
    "\n",
    "input_array_1 = np.random.rand(arg_size)\n",
    "input_array_2 = np.random.rand(arg_size)\n",
    "result_array = np.zeros_like(input_array_1)\n",
    "\n",
    "# do single-threaded naive nested for loop\n",
    "# reset result_array inside %timeit call \n",
    "%timeit -r 3 result_array[:] = 0.0; naive_for_loop(input_array_1, input_array_2, result_array)\n",
    "result_1 = result_array.copy()\n",
    "\n",
    "# do single-threaded forall loop (loop indices in-order)\n",
    "# reset result_array inside %timeit call \n",
    "loop_indices = range(arg_size)\n",
    "%timeit -r 3 result_array[:] = 0.0; forall_loop_body_cpu(input_array_1, input_array_2, loop_indices, result_array)\n",
    "result_2 = result_array.copy()\n",
    "\n",
    "# do multi-threaded forall loop (loop indices in-order)\n",
    "# reset result_array inside %timeit call \n",
    "loop_indices = range(arg_size)\n",
    "%timeit -r 3 result_array[:] = 0.0; forall_loop_body_parallel(input_array_1, input_array_2, loop_indices, result_array)\n",
    "result_3 = result_array.copy()\n",
    "\n",
    "# do forall loop (loop indices scrambled for better load balancing)\n",
    "# reset result_array inside %timeit call \n",
    "loop_indices_scrambled = np.random.permutation(range(arg_size))\n",
    "loop_indices_unscrambled = np.argsort(loop_indices_scrambled)\n",
    "%timeit -r 3 result_array[:] = 0.0; forall_loop_body_parallel(input_array_1, input_array_2, loop_indices_scrambled, result_array)\n",
    "result_4 = result_array[loop_indices_unscrambled].copy()\n",
    "\n",
    "\n",
    "# check validity\n",
    "print(np.all(result_1 == result_2))\n",
    "print(np.all(result_1 == result_3))\n",
    "print(np.all(result_1 == result_4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<link href='http://fonts.googleapis.com/css?family=Fenix' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Alegreya+Sans:100,300,400,500,700,800,900,100italic,300italic,400italic,500italic,700italic,800italic,900italic' rel='stylesheet' type='text/css'>\n",
       "<link href='http://fonts.googleapis.com/css?family=Source+Code+Pro:300,400' rel='stylesheet' type='text/css'>\n",
       "<link href=\"https://fonts.googleapis.com/css?family=Oswald|Raleway\" rel=\"stylesheet\" type='text/css'> \n",
       "<style>\n",
       ".prompt{\n",
       "    display: none !important;\n",
       "}\n",
       "\n",
       ".rendered_html pre {\n",
       "    border: 1px solid #f0f6f9 !important;\n",
       "}\n",
       "\n",
       ".rendered_html pre, .rendered_html code {\n",
       "    background-color: #d3d8db !important;\n",
       "    padding: 1% !important;\n",
       "    line-height: 200% !important;\n",
       "    border-radius: 10px !important;\n",
       "}\n",
       "\n",
       "div.input_area {\n",
       "    border-radius: 10px !important;\n",
       "    background-color: #e1e1e6 !important;\n",
       "}\n",
       "\n",
       "div.cell{\n",
       "        width:85% !important;\n",
       "        margin-left:5% !important;\n",
       "        /*margin-right:auto;*/\n",
       "    }\n",
       "    h1, h2, h3, h4, h5 {\n",
       "        font-family: 'Oswald', sans-serif; !important;\n",
       "        font-style: oblique !important;\n",
       "    }\n",
       "    div.text_cell_render{\n",
       "        font-family: 'Raleway', sans-serif; !important;\n",
       "        line-height: 135% !important;\n",
       "        font-size: 120% !important;\n",
       "        width:100%;/*600px;*/\n",
       "        /*margin-left:auto;*/\n",
       "        /*margin-right:auto;*/\n",
       "    }\n",
       "    .CodeMirror{\n",
       "            font-family: \"Source Code Pro\" !important;\n",
       "\t\t\tfont-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render p{\n",
       "        text-align: justify !important;\n",
       "    }\n",
       "    .text_cell_render h1 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 10.em !important;\n",
       "        margin-top: 50.em !important;\n",
       "        padding-bottom: 50.em !important;\n",
       "        padding-top: 50.em !important;\n",
       "        display: block !important;\n",
       "        font-size: 300% !important;\n",
       "        text-align: center !important;\n",
       "        border-bottom: 1px solid #47597A !important;\n",
       "        border-top: 1px solid #47597A !important;\n",
       "    }\n",
       "    .text_cell_render h2 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 200% !important;\n",
       "        border-bottom: 1px solid #47597A !important;\n",
       "    }\n",
       "    .text_cell_render h3 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 200% !important;\n",
       "    }\n",
       "    .text_cell_render h4 {\n",
       "        font-style: italic !important;\n",
       "        font-weight: bold !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        display: block !important;\n",
       "        font-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render h5 {\n",
       "        font-weight: 200 !important;\n",
       "\t\tline-height: 100% !important;\n",
       "        color:#47597A !important;\n",
       "        margin-bottom: 0.5em !important;\n",
       "        margin-top: 0.5em !important;\n",
       "        display: block !important;\n",
       "        font-size: 100% !important;\n",
       "    }\n",
       "    .text_cell_render ul {\n",
       "\tlist-style-type: disc !important;\n",
       "\tcolor:#47597A !important;\n",
       "    }\n",
       "    .warning{\n",
       "        color: rgb( 240, 20, 20 ) !important;\n",
       "        }\n",
       "</style>\n",
       "\n",
       "<script>\n",
       "    MathJax.Hub.Config({\n",
       "                        TeX: {\n",
       "                           extensions: [\"AMSmath.js\"],\n",
       "                           },\n",
       "                tex2jax: {\n",
       "                    inlineMath: [ ['$','$'], [\"\\\\(\",\"\\\\)\"] ],\n",
       "                    displayMath: [ ['$$','$$'], [\"\\\\[\",\"\\\\]\"] ]\n",
       "                },\n",
       "                displayAlign: 'center', // Change this to 'center' to center equations.\n",
       "                \"HTML-CSS\": {\n",
       "                    styles: {'.MathJax_Display': {\"margin\": 4}}\n",
       "                }\n",
       "        });\n",
       "</script>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# execute this part to modify the css style\n",
    "from IPython.core.display import HTML\n",
    "def css_styling():\n",
    "    styles = open(\"./style/custom.css\").read()\n",
    "    return HTML(styles)\n",
    "css_styling()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "@vectorize(['float64(float64, float64)'], target='parallel')\n",
    "def sincos_vec(x, y):\n",
    "    return math.cos(x)*math.sin(y)\n",
    "\n",
    "@guvectorize(['(float64[:], float64[:], float64[:])'], '(), () -> ()', target='parallel')\n",
    "def sincos_gu(x, y, out):\n",
    "    out[0] = math.cos(x[0])*math.sin(y[0])\n",
    "\n",
    "@njit\n",
    "def sincos_jit(x, y, out):\n",
    "    for i in range(x.size):\n",
    "         out[i] = math.cos(x[i])*math.sin(y[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = np.linspace(0, 2*math.pi, 1000000)\n",
    "y = np.linspace(0, 2*math.pi, 1000000)\n",
    "out_jit = np.zeros_like(x)\n",
    "out_vec = np.zeros_like(x)\n",
    "out_gu = np.zeros_like(x)\n",
    "\n",
    "out_vec = sincos_vec(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 67.1 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sincos_vec(x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 loop, best of 3: 213 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sincos_jit(x, y, out_jit)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 loops, best of 3: 72.5 ms per loop\n"
     ]
    }
   ],
   "source": [
    "%timeit sincos_gu(x, y, out_gu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(np.all(out_vec == out_jit))\n",
    "print(np.all(out_vec == out_gu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
